{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "(usethis) USE-NLP_malware_detection-Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinajacquelyn/USE-Malware-Detection/blob/master/USE_NLP_malware_detection_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H33AKtDu-7FK",
        "colab_type": "text"
      },
      "source": [
        "### 1. Pre-processing\n",
        "\n",
        "#### 2. tokenisation\n",
        "#### 3. remove stop words\n",
        "#### 4. encode label\n",
        "#### 5. word embeddings\n",
        "\n",
        "#### 6. build a CNN (convolutional neural network) model\n",
        "\n",
        "### 7. Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf4_mLZT-7Fg",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "https://towardsdatascience.com/problems-in-machine-learning-models-check-your-data-first-f6c2c88c5ec2\n",
        "https://www.quora.com/Should-I-also-do-data-preparation-transformation-on-the-test-set-in-machine-learning-If-not-my-train-and-test-set-would-look-entirely-different-Can-an-algorithm-process-that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtOMcKm-7Fq",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcCNLrKQ-7F4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining paths to Data and Labels\n",
        "TEXT_DIR=\"malware_text_89.txt\"\n",
        "LABEL_DIR=\"label_88.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjBGTuGybEKN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfOtT85Q-7Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(TEXT_DIR, LABEL_DIR):\n",
        "    text = pd.read_csv(TEXT_DIR, sep=\"\\n\", header=None)\n",
        "    text.columns=['sentence']                              # label text column as 'sentence'\n",
        "    label = pd.read_csv(LABEL_DIR)\n",
        "    return text, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okNq-6xKcXA7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVY3tTMs-7HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text, label = load_data(TEXT_DIR, LABEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khsvTGue-7Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del label['ioc_type']\n",
        "# del label['value']\n",
        "# del label['family']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8qNGpcywKzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvtzs2yu-7H-",
        "colab_type": "code",
        "outputId": "786eda6c-22aa-4650-9835-f1464f79c892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# View some Text\n",
        "print(text.tail(), '\\n')\n",
        "text.iloc[0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              sentence\n",
            "114  On Nov. 12, we saw an interesting attack that ...\n",
            "115  As the research progressed, more and more thre...\n",
            "116  ZDNet reported that the list consists of IP ad...\n",
            "117  The hacker composed the list by scanning the i...\n",
            "118  Using IoT search engines, ZDNet was able to ve... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The attacks associated with the new botnet att...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>About 12 hours ago (2017-12-05 11:57 AM GMT+8)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence\n",
              "0  The attacks associated with the new botnet att...\n",
              "1  About 12 hours ago (2017-12-05 11:57 AM GMT+8)..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6rCuUJ6-7It",
        "colab_type": "code",
        "outputId": "c95348b1-b605-4976-c81c-0e4251c2fa7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "text.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The attacks associated with the new botnet att...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>About 12 hours ago (2017-12-05 11:57 AM GMT+8)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Two new exploits, which work on port 37215 and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As can be seen from the following picture, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>During the scanning, Satori will utilize two d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence\n",
              "0  The attacks associated with the new botnet att...\n",
              "1  About 12 hours ago (2017-12-05 11:57 AM GMT+8)...\n",
              "2  Two new exploits, which work on port 37215 and...\n",
              "3  As can be seen from the following picture, the...\n",
              "4  During the scanning, Satori will utilize two d..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0GV5-n3-7JS",
        "colab_type": "code",
        "outputId": "48beba00-c4d8-4caf-ec3b-1fb3f3a4a196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "label.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>malware</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mirai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mirai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mirai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mirai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mirai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  malware\n",
              "0   Mirai\n",
              "1   Mirai\n",
              "2   Mirai\n",
              "3   Mirai\n",
              "4   Mirai"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HDAJc6zZhPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyMxvWpn-7Jt",
        "colab_type": "code",
        "outputId": "08a00e63-86c0-4d7e-b042-d9a6a8b818c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "# View some Labels\n",
        "print(label.columns, '\\n')\n",
        "print(label.iloc[0])\n",
        "label.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['malware'], dtype='object') \n",
            "\n",
            "malware    Mirai\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>malware</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>nil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>nil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>nil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>nil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>nil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    malware\n",
              "114     nil\n",
              "115     nil\n",
              "116     nil\n",
              "117     nil\n",
              "118     nil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_xYAkdM-7KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting specific data; values of ioc types\n",
        "# ioctypes = label['ioc_type'].values\n",
        "# ioctypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3HkgFZv-7K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Getting specific data; rows where value == '8080'\n",
        "# port8080s = label[label['value'] == '37215']\n",
        "# port8080s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL33joxM-7Lk",
        "colab_type": "code",
        "outputId": "f7c1cc6c-7b1f-4720-e34b-18ae287140b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "label.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Mirai'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['Emotet'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil'],\n",
              "       ['nil']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-qlllU9-7Mm",
        "colab_type": "code",
        "outputId": "3e8fdb6f-4a2a-4d7d-ca51-133f0e1388c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text['sentence'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['The attacks associated with the new botnet attempted to exploit the CVE-2017-17215 zero-day vulnerability in the Huawei home router caused by the fact that the TR-064 technical report standard, which was designed for local network configuration, was exposed to WAN through port 37215 (UPnP – Universal Plug and Play).',\n",
              "       'About 12 hours ago (2017-12-05 11:57 AM GMT+8), we noticed a new version of Satori (a mirai variant which we named Satori), starting to propagate very quickly on port 37215 and 52869. This new variant has two significant differences from known mirai variants: The bot itself now does NOT rely on loader|scanner mechanism to perform remote planting, instead, bot itself performs the scan activity. This worm like behavior is quite significant.',\n",
              "       'Two new exploits, which work on port 37215 and 52869 have been added, see below for more details. Due to the worm like behavior, we all should be on the lookout for the port 37215 and 52869 scan traffic. (For those who don’t have the visibility, feel free to check out our free Scanmon system for port 37215 and 52869, or ISC port pages for 37215 and 52869.',\n",
              "       'As can be seen from the following picture, the bot will scan port 37215 and 52869 randomly, determined by the remainder of a random integer mod 3.',\n",
              "       'During the scanning, Satori will utilize two different exploits, one on port 37215, while the other on 52869. The one on port 37215 is not fully disclosed yet, our team has been tracking this in the last few days and got quite some insight, but we will not discuss it here right now.(stay tuned for our update later).',\n",
              "       'The scanning IP (aka, the bot) numbers are now climbing straight up. For example, during last recent 12 hours we have seen 263,250 different IPs scanning port 37215, and 19,403 IPs scanning port 52869.',\n",
              "       'We analyzed another Mirai variant called “Miori,” which is being spread through a Remote Code Execution (RCE) vulnerability in the PHP framework, ThinkPHP. The exploit related to the vulnerability is relatively new — details about it have only surfaced on December 11. For its arrival method, the IoT botnet uses the said exploit that affects ThinkPHP versions prior to 5.0.23 and 5.1.31.',\n",
              "       'Miori is just one of the many Mirai offshoots. Fortinet once described its striking resemblance to another variant called Shinoa. Our own analysis revealed that the cybercriminals behind Miori used the ThinkPHP RCE to make vulnerable machines download and execute their malware.',\n",
              "       'With Mirai Comes Miori: IoT Botnet Delivered via ThinkPHP Remote Code Execution Exploit.',\n",
              "       'Miori now spreading via Remote code execution vulnerability in the PHP framework called ThinkPHP and the exploit for this vulnerability is completely new that affected ThinkPHP versions prior to 5.0.23 and 5.1.31.',\n",
              "       'Apart from this, several Mirai malware various are being distributed by exploiting the same ThinkPHP RCE vulnerability. Infection distributed via other connected device by reset the default credentials via telnet also researcher learned that it affected one of the linux machine to perfromDDOS attack.',\n",
              "       'The Miori bot borrows the code from the dreaded Mirai malware and it first appeared in the threat landscape in late 2018 when the bot was spread by exploiting a ThinkPHP remote code execution vulnerability after the exploit code was made publicly available.',\n",
              "       'Among the list of devices targeted by the Wicked Mirai are Netgear DGN1000 and DGN2200 v1 routers (also used by Reaper botnet).',\n",
              "       'The exploit to be used depends on the specific port the bot was able to connect to. Specifically, port 8080 brings an exploit for a flaw in Netgear DGN1000 and DGN2200 v1 routers (also used by the Reaper botnet).',\n",
              "       'The used exploit depends on the specific port that the connection was established to. On port 8080, the malware uses Netgear DGN1000 and DGN2200 v1 router exploits (also used by Reaper botnet).',\n",
              "       'While the original version of Mirai used brute force techniques to compromise devices, Wicked relies on known exploits — used depending on the port the bot is connected to. If connected to Port 8080, the malware will use a remote code execution (RCE) Netgear exploit which works on DGN1000 and DGN2200 v1 routers, and is the same tool used by the Reaper botnet to compromise target machines.',\n",
              "       'Once the connection is made, attempts are made to exploit vulnerabilities to download the malicious payload by writing exploit strings to the socket. Different exploits are used depending on the port where the connection was established. On port 8080, Netgear DGN1000 and DGN2200 v1 router exploits are used, a CCTV-DVR remote code execution exploit is used on port 81,',\n",
              "       'The experts discovered that the exploit to be used depends on the specific port the bot was able to connect to. Below is a list of devices targeted by the Wicked Mirai; Port 8080: Netgear DGN1000 and DGN2200 v1 routers.',\n",
              "       'Devices Targeted by Wicked include Netgear DGN1000 and DGN2200 v1 routers on Port 8080.',\n",
              "       'Appropriately dubbed “Wicked,” the variant relies on known exploits, as opposed to the previous version which used brute force techniques to compromise devices. When connected to Port 8080, the malware uses a remote code execution (RCE) Netgear exploit which works on DGN1000 and DGN2200 v1 routers.',\n",
              "       'Emotet has used ports 20, 22, 80, 443, 8080, and 8443.',\n",
              "       'The dissection of this suspicious file, known by Symantec as Trojan.Emotet, shows common elements such as: TCP communication over ports 80, 8080, 22,990.  (it’s assumed that one of those will be C&C and others used to collect info)',\n",
              "       'After initial installation, the C2 capabilities begin. Emotet connects to C2 servers on various ports including, but not limited to: 20, 80, 443, 7080, 8443, and 50000. Typically, this all occurs using HTTP traffic to hard-coded IP addresses similar to what is shown below.',\n",
              "       'We can see that port 80 returns the same universal 404 error as the hacked server did on the Emotet port, so most likely this is the port it forwards traffic to. Next question is, could this be the origin server or is it just another reverse proxy?',\n",
              "       'The C2 servers can receive these communications on port 80, which is the default port for HTTP, but may also receive them on port 443, which is the default for HTTPS traffic, or on a number of other nonstandard ports, including but not limited to 7080, 8080, 8090, 50000, or several others. The initial executable appears to launch an application application lpiograd.exe, seen in Figure 2 and then looks to make outbound network connections on port 80, to a single command and control (CnC) server.',\n",
              "       'The initial executable appears to launch an application application lpiograd.exe, seen in Figure 2 and then looks to make outbound network connections on port 80, to a single command and control (CnC) server',\n",
              "       'Emotet Trojan used commonly used port for communication (e.g TCP port 80, 8080, 443, 8443, 7080, 20, 22, 53)',\n",
              "       'The following are indicators (IP addresses, domain names, and file hashes) associated with the infection of my Windows lab host. Traffic from the Emotet infection. 5.101.138.188 port 80 - sloegincottage.co.uk - GET /tyoinvur/En_us/Clients/092018/',\n",
              "       'After gaining the persistency and enumerating the compromised host the next stage of Emotet is to connect to a new IP address on port 80.',\n",
              "       'Another new wrinkle included using HTTP 301 redirects, but the reason is not known at this time. Emotet then connects itself to C2 servers that use special ports 20, 80, 443, 7080, 8443, and 50000. The malware will make sure its victim’s IP address is on a blacklist or if they use a spam list service such as Spamhaus, SpamCop, and SORBS.',\n",
              "       'Successor of Feodo, completely different code. Hosted on the same botnet infrastructure as Version A (compromised webservers, nginx on port 8080 TCP or port 7779 TCP, no domain names) but using a different URL structure. This Version is also known as Geodo and Emotet.',\n",
              "       'It is important to note that though we may not observe all the traffic to the Tier 2 C2s, we do observe traffic patterns from Tier 1 C2s that cross our network. Based on our visibility over the last 30 days, 14 IPs communicated with 5.45.65[.]126 on port 80/TCP, 13 of which were validated Tier 1 C2s.',\n",
              "       'Traffic observed to 212.8.242[.]201 was similar, with 23 IPs communicating on port 80/TCP, 22 of which were validated Tier 1 C2s.',\n",
              "       'In the last month, the cybercriminals behind the Emotet infection have changed the ways they launch these types of attacks and how they evade detection. One technique is by simply swapping a .doc file with a .docx, which can make static detection of maldocs more difficult due to the compression native in the .docx format. This high-level change, combined with smaller changes in how their binary packer, command and control, embedded OLE objects, process names and powershell obfuscation are occurring, make tracking them and writing defensive signatures an ongoing challenge.',\n",
              "       'While the attached documents all have a .doc extension, they are in fact .dotm, .docx, and other document file types, which enables them to successfully hide the embedded objects as ActiveX objects rather than typical “Form” objects whose metadata can be easily accessed in an opened document. In each case, the result is the attempted download of an Emotet binary from a set of five payload locations using both HTTP and HTTPS. Emotet has been seen downloading TrickBot and other malware historically, with no noteworthy modifications to the present-day TrickBot sample.',\n",
              "       '[F00000000][T01D19C127D907AA0][O00000000]*%USERPROFILE%\\\\Desktop\\\\New Microsoft Word Document.docx',\n",
              "       'The attachment is an XML file masquerading as a .doc with embedded macros leading to a standard PowerShell downloader normally observed with Emotet banking Trojan, which is also used by crooks to drop other payloads. However, the document in this case is not the usual .doc or .docx but rather an XML file masquerading as a .doc, and the macro in this instance makes use of the Shapes feature,',\n",
              "       'Threat researchers with Kaspersky identified other attempts to spread Emotet using the coronavirus scare as a way to get people to open emails or files and share them. Cybercriminals are attaching .pdf, .mp4, and .docx files to emails that purport to have information on how people can protect themselves from the virus, updates on its spread and even virus detection procedures.',\n",
              "       'The Emotet malware will disguise itself as a website hyperlink or regular file attachment in an email (.doc, .docx, .PDF), that will include hidden code that enables cybercriminals to gain control of your computer and other devices, often leading to the deployment of ransomware. This type of malware will only infect your computer or other devices if users click on those hyperlinks or open the file attachments. Please be aware that these emails are very sophisticated and are tailored to look like they were sent from a person you know or an organisation you have a relationship with.',\n",
              "       'Known as Emotet, the trojan is attached under the guise of pdf, mp4 and docx files. Users who open the document are infected with the malware, which can go undetected by antivirus software. Increasing the likelihood of further infection, emotet can also forward itself to every email contact of a victim, meaning recipients may feel safe to click on any links or documents as they appear to have come from a trusted contact.',\n",
              "       'Emotet is most commonly spread via malicious emails containing Microsoft Office attachments, usually Microsoft Word (.doc, .docx) documents. These attached files contain macros that download and install the Emotet malware when opened. Emotet can also be spread via embedded URLs in malicious emails. The ACSC has received reports of Emotet being spread through both untargeted bulk spam emails, as well as what appear to be highly targeted spear-phishing emails.',\n",
              "       'If the user has not enabled macros, a popup window will appear asking the user to click to do so. The pop-up is one of several security mechanisms added by Microsoft to mitigate the security risk that macros pose. Microsoft will also force a different file extension (.docm instead of .docx for new documents containing macros). Despite these measures, users still choose to open these files and enable their content, thus allowing macros to continue be a common attack vector – both in wide and simple attacks to deliver ransomware such as Emotet, as well as for sophisticated attacks like this Sofacy campaign.',\n",
              "       'It is most commonly spread via Microsoft Office attachments, usually Microsoft Word (.doc, .docx) documents.  However, the email has been spoofed in order for the target to trust the email and attempt to open the attachment. Furthermore, the bottom of the email tricks the receiver into thinking that the email is not malicious by stating that it has been scanned with antivirus.',\n",
              "       'In HKEY_CURRENT_USER\\\\Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Explorer\\\\FileExts\\\\.docx\\\\OpenWithProgids',\n",
              "       'Also, security experts at Kaspersky identified this malware spreading in form of pdf, mp4 and Docx files. These types of files come with the title- “video instructions on how to protect yourself from the virus”, “updates on the threat” and “virus detection procedures”.',\n",
              "       'According to security firm Kaspersky, attackers are using several types of malicious files, including pdf, mp4 and docx with “coronavirus” theme to spread malware. Many of the files used in the attacks observed by the experts in these hours are presented as documents containing information about the virus, its diffusion, and instructions on how to prevent the contagion.',\n",
              "       'This configuration is the first thing checked by this module. In particular, the registry key HKLM\\\\Software\\\\Clients\\\\Mail\\\\Microsoft Outlook is accessed, and the value DllPathEx—the path to the mapi32.dll module—is expected to be defined. If it is not, the module does not proceed.',\n",
              "       'Old Emotet malware checks the configuration module of the email client especially the registry key HKLM\\\\Software\\\\Clients\\\\Mail\\\\Microsoft Outlookto exfiltrate the Email data.',\n",
              "       'The first step to check if it is infected is to look at the configuration - the path to the DllPathEx-mapi32.dll module, especially the HKLM\\\\Software\\\\Clients\\\\Mail\\\\Microsoft Outlook access registry key. If not, the module will not continue. The registry keys that need attention are very specific, and other plausible items do not require special attention.',\n",
              "       'When this module is executed, it checks for the presence of registry key HKLM\\\\Software\\\\Clients\\\\Mail\\\\MicrosoftOutlook and then checks value of DLLPathEx i.e. the path to the mapi32.dll module.',\n",
              "       'Provides information about used mail client (read from “HKLM\\\\Software\\\\Clients\\\\Mail” registry key value) and if it’s Microsoft Outlook and it’s MAPI DLL is 64-bit, name is followed by ” x64″ suffix.',\n",
              "       \"Emotet's module when executed checks for the presence registry key HKLM\\\\Software\\\\Clients\\\\Mail\\\\Microsoft Outlook and accesses, expecting the DllPathEx value to be defined.\",\n",
              "       'PPTP (Point-to-Point Tunneling Protocol) is used to provide IP security at the network layer. PPTP uses TCP 1723 to set up the connection, but uses GRE (protocol 47) for the user traffic',\n",
              "       'Zeus’ main vectors are mail spam, malicious social engineering and by inserting itself into legitimate product downloads, also known as drive-by downloads.',\n",
              "       'However, in a blog post published last week, security researchers at BinaryDefense have made a pretty important discovery that\\'s surely to give many system administrators headaches for the foreseeable future -- namely an Emotet module that under certain circumstances can jump the WiFi gap to nearby networks. The new Emotet \"WiFi spreader\" module (as it was called) does not guarantee an 100% infection rate, as it relies on users utilizing weak passwords for their WiFi networks, however, it opens a new attack vector inside infected companies that the Emotet gang can exploit to maximize their reach.',\n",
              "       'Mirai botnet variants include Satori, Okiru, Masuta, PureMasuta, OMG, IoTroop, Wicked, JenX, Fbot, Torii, Miori, and Yowai. Mirai infects unsecured internet of things (IoT) devices such as DVR’s, IP Cameras, Wi-Fi routers and many other home automation devices connected to the Wifi network.',\n",
              "       'Mirai variant Masuata and its sub-variant PureMasuta leverages SOAP exploit to persuade targeted devices to run commands issued by the attacker.  PureMasuta targeted a specific vulnerability on D-Link routers. It also exploited a known vulnerability in HNAP (Home Network Administration Protocol), which is based on SOAP.',\n",
              "       'OMG turns infected devices into proxy servers and provides a network of proxy servers for rent to several cybercriminals who are looking for DDoS generators, a SPAM network, crypto-jacker scheme, or ransomware empire. OMG variant has the capability to check for and rewrite firewall rules to ensure that the ports used by the new proxy server can transit the network perimeter without any trouble. It can also look for open ports and kill any processes related to telnet, HTTP, and SSH and use telnet brute-force logins to spread.',\n",
              "       'In simple words, a port number is a 16-bit numeric value that oscillates between 0 and 65535. There are three different types of port number spaces: well known ports (0-1023), registered ports (1024-49151) and dynamic ports (49152-65535). These ports can be opened and used by software application and operating system services under certain protocols (e.g. TCP, UDP) across the network (LAN or WAN) to send and receive information.',\n",
              "       'This study also concludes that a total of 377 Portuguese domains to spread different types of malware in the same period. Analyzing the general distribution of the compromised domains, grouped by category, it is possible to verify that the most affected were as follows: professional/companies (20.2%), personal (13.5%), retail (12.7%) and industry (11.9%).',\n",
              "       'In this case the infected host 192.168.1.100 (which is the Windows XP machine where the sample was run) is sending the encrypted traffic to C2 (192.168.1.2 which is my Linux machine acting as C2) on port 2011, also in this case the magic keyword “Gh0st” was sent in the first 5 bytes',\n",
              "       'This is followed by SSL/TLS traffic over ports 447 and/or 449. Depending on the type of traffic it will either connect to TCP447, TCP449 or TCP8082 mixed with traffic over normal HTTP/HTTPS ports.',\n",
              "       'Using the port 53281 as filter to our NetFlow, it became obvious that inbound traffic towards the C2 could be placed into two categories, anonymous proxy and infected traffic',\n",
              "       'Traffic over ports 443 and 449 to the IPs in the IOC section are an atomic indication of Trickbot [6], worthy of tracking and identifying hosts for investigation.',\n",
              "       'Monitoring and logging PowerShell events on Windows is good practice and works best with endpoints having PowerShell 5.0 installed. Both Script Blocks logging and Module logging are the auditing options to set. See PowerShell Auditing in the appendix',\n",
              "       'While it’s difficult for AV to trace polymorphic packed malware, IDS solutions such as Bro/Zeek now include integration with JA3 for SSL string hashes to match Trickbot traffic',\n",
              "       'The password grabber and some other TrickBot modules send stolen data using unencrypted HTTP over TCP port 8082 to an IP address used by TrickBot',\n",
              "       'PoisonIvy opens a backdoor on TCP ports 6868 and 7777.',\n",
              "       'A TYPEFRAME variant can use port 127 for communications.',\n",
              "       \"The Emotet payload was delivered onto the targets' computers using malicious emails which come with zipped up Powload Trojan attachments which will download the Emotet executable after being launched.\",\n",
              "       'Before this was implemented, Emotet would use \"an HTTP GET request to send victim information to the C&C server, and the data is stored in the Cookie header.',\n",
              "       'There is a total of 65,535 TCP ports and another 65,535 UDP ports; we’ll look at some of the diciest ones.',\n",
              "       'Oddly enough, Emotet does communicate over ports such as 22, 8080 and 443 where unencrypted HTTP transmissions are not common and yet still often evades detection.The Walt Disney Company announced this afternoon that Robert Iger, the company’s long-time CEO who ushered in the company’s lush franchise and entertainment platform profits, will step down immediately as chief executive.',\n",
              "       'Bob Chapek, a long-time senior exec at the company who most recently held the position of chairman of Disney Parks, Experiences and Products, will succeed him.',\n",
              "       'Chapek, as head of Disney’s Parks Division, was a somewhat divisive figure in that he led with a “value engineering” (the Imagineering word for trimming cool stuff) and budget conscious strategy instead of the more popular “let Imagineers do the most” tactic that has produced some of the parks’ most enduring rides and experiences. Disney Twitter has been quick to descend upon the Chapek choice as a sign of possible rough times ahead for Parks budgets.',\n",
              "       'Our guess for who would head Parks is Josh D’Amaro, extremely-well liked former head of Disneyland who now heads Walt Disney World — liked by Parks people for a lot of the opposite reasons, which politically could make this a non starter, but would be a very popular appointment.',\n",
              "       'A few oddities surround this sudden change. Iger is only 14 months into a 36-month contract extension, and this comes not on a regularly scheduled earnings call but in the midst of an interesting time for Disney, as it faces parks shutdowns due to the coronavirus outbreak. Disney’s earnings have been amazing lately, which would have made for a nice two-hander at earnings time. Speculation is still high for the exact reason behind Iger’s departure, with many hoping for something benign (ish) like a presidential run versus a personal issue.',\n",
              "       'Iger will address Disney employees at 5:30EST today, and we’ll update if anything further comes of that address.',\n",
              "       'Under Iger’s tenure since 2005, Disney expanded aggressively into movies, theme parks and other entertainment verticals, culminating late last year with the introduction of the company’s Disney+ streaming service and $71.3 billion acquisition of 21st Century Fox, a gargantuan television and movie studio.',\n",
              "       'Iger oversaw such dramatic acquisitions as Marvel Entertainment  a little more than a decade ago, and also bought Lucasfilm and its Star Wars and Indiana Jones series. He also helped to rebuild a partnership with late Apple founder and CEO Steve Jobs, and eventually acquired the Pixar animation studio, which Jobs had founded in 1986. Those decisions, among other aggressive media growth strategies, have given Disney a commanding role in the media universe.',\n",
              "       'As Jake Coyle noted in the AP earlier this year:  But in today’s IP-driven movie world, one studio is in a league of its own. In 2019, Disney dominated American moviegoing more than any studio ever has before — roughly 38% of all domestic moviegoing.',\n",
              "       'The year’s top five films were all Disney movies, and it played a hand in the sixth. Disney’s Marvel Studios produced the Sony Pictures release “Spider-Man: Far From Home.”  Since its launch, Disney+ itself has drawn almost 30 million subscribers, according to data released by the company earlier this month.',\n",
              "       'Disney+ already has 28.6M subscribers  Iger will assume the role of executive chairman through 2021 according to Disney’s statement.',\n",
              "       'It has been no secret that Iger has been thinking about succession planning for years, but at least until recently, details had remained scant. Media analysts probed for news in Iger’s book “The Ride of a Lifetime,” which was published late last year and was a summation of his tenure at the media conglomerate and his business philosophy. Yet, finding a successor at the company has been challenging, with multiple heirs apparent departing the company when the top slot looked like it would remain locked in Iger’s grasp.',\n",
              "       'Disney to “broaden the scope” of succession planning as its COO departs  On an already heavy red-ink day, Disney stock was further hit in after-hours trading by investors.',\n",
              "       'Yahoo Finance’s most recent quotes puts Disney stock down 2.57% in after-hours trading, following a 3.62% decline during trading hours stemming from the global coronavirus outbreak.',\n",
              "       'Disney has significant properties in Asia, including Shanghai Disney Resort, which was the company’s first platform in China and was overseen by incoming CEO Chapek.',\n",
              "       'Update: Here’s Bob Iger’s letter to Disney employees.',\n",
              "       'Dear Fellow Employee, Today the Board of Directors announced that Bob Chapek  has been named Chief Executive Officer of The Walt Disney Company, effective immediately. I have assumed the role of Executive Chairman and will continue to direct the Company’s creative endeavors, while also leading the Board. This is an exciting day for our company, an historic day—and I’m thrilled for Bob. I’ve worked closely with him for many years and have absolute confidence in his abilities, as does the Board.',\n",
              "       'As CEO, Bob will oversee all of the Company’s business segments and corporate functions, and we will work closely together through the end of 2021 to further the Company’s strategic objectives and to ensure a smooth and successful transition. Bob has been with Disney for nearly three decades, and during this time he has achieved stellar results across a wide array of businesses. Throughout he’s led with integrity and conviction, always respecting Disney’s rich legacy, while at the same time taking smart, innovative risks for the future.',\n",
              "       'As president of Home Entertainment for the Studio, he spearheaded the highly successful “vault strategy” that brought Disney’s iconic films and characters to new generations of viewers. As president of distribution for the Studio, he directed the Company’s film distribution strategy and expanded our global reach across multiple platforms. As head of Consumer Products, he transformed the business, focusing it on our key franchises and embracing technological innovation to deliver unmatched consumer experiences.',\n",
              "       'Most recently, as Chairman of Parks, Experiences and Products, he oversaw the largest capital expansion in the history of our parks that included the opening of Shanghai Disney Resort, a doubling of the Disney Cruise Line fleet, and the creation of the new Star Wars: Galaxy’s Edge lands at Disneyland and Walt Disney World. Bob has worked closely and collaboratively with leaders across the different segments of our company, and I’m confident he will apply the same vision, passion and commitment to excellence in his new role as Chief Executive Officer.',\n",
              "       'I’ve had the tremendous privilege of being CEO for the past 15 years, and it’s been thrilling for me to be part of such an exciting and productive era for our company.',\n",
              "       'I’m enormously proud of all that we’ve accomplished, creatively, financially and strategically—including the acquisition of Twenty-First Century Fox and the incredibly successful launch of our direct-to-consumer businesses. With these key endeavors well underway, I believe it’s the right time to transition to a new CEO and I believe Bob is absolutely the right person to assume this role and lead our company in this next pivotal period.',\n",
              "       'I am certain that under his leadership, our portfolio of great businesses and our amazing and talented people will continue to serve our company and our shareholders well into the future.',\n",
              "       'I congratulate Bob and look forward to working with him in his new role as CEO, along with the other members of our amazing leadership team.',\n",
              "       'Bob and I will hold a town hall meeting tomorrow in the Main Theatre at 9 a.m. PT. To RSVP for the theater or to view the live webcast, please click here. My thanks and best to you all, Bob Matthew Panzarino contributed additional details about Chapek and context around Disney’s succession.',\n",
              "       'As almost always these days, the hackers have mounted a phishing campaign to exploit weaknesses in non-hardened, non-governmental sectors. Defensive holes, lack of patching, network and IoT vulnerabilities and poor user training come to the fore. The objective is not political, it’s financial.',\n",
              "       'The alert includes malware analysis reports (MARs) for seven trojans “designed to enable network defenders to identify and reduce exposure to North Korean government malicious cyber activity.” U.S. individual users and security teams within U.S. organizations are being urged to look for activity that fits these patterns, giving the activity “the highest priority for enhanced mitigation.”',\n",
              "       'If allowed to take root, the various strains of malware enable remote access to machines and networks, the download of further malicious software, as well as the exfiltration of credentials and files.',\n",
              "       'It is assumed that the same attackers thought responsible for the WannaCry ransomware attack in 2017 are likely behind these latest campaigns—referred to as Lazarus by the private sector and “Hidden Cobra” by the U.S. government.',\n",
              "       'AV-TEST’s findings paint a picture of a threat landscape flooded with malware. While threat actors can use these samples to get up to trouble in any old way, it’s likely that more and more criminals will flock to certain channels rather than others over the coming year.',\n",
              "       'We have two main reasons to anticipate that fileless malware attacks will become more commonplace in 2020. First, the security community observed an increase in fileless attacks over the previous year. Trend Micro noted in September 2019 that detections of fileless attacks across H1 2019 had increased by 265 percent over the previous year, for instance.',\n",
              "       'Second, security researchers tracked more categories of digital threats beginning to incorporate fileless techniques into their attack chains. For instance, Malwarebytes revealed in November 2019 that a growing number of exploit kits had begun using fileless attacks instead of dropping their payloads onto a disk.',\n",
              "       'Ransomware is bad enough when it encrypts a victim’s data and demands a ransom payment in exchange for the decryption key. Not all ransomware families stop there, however. Some families have specifically begun punishing users who don’t fulfill their ransom demands.',\n",
              "       'In publishing Allied Universal’s data online, the Maze group apparently inspired other ransomware families to follow suit. Sodinokibi took the lead by leaking 337 MB of data stolen from Artech Information Systems in early January 2020.',\n",
              "       'The digital security solutions provider found that admins had protected just 10 of the 187 election-related domains with DMARC, a protocol useful for validating a sender’s authenticity.',\n",
              "       'The Cybersecurity Infrastructure Security Agency (CISA) is concerned about this possibility. In particular, it’s worried that malicious actors could use ransomware to lock up and/or destroy states’ voter registration databases. That explains why CISA announced its intention in August 2019 to create a program for helping states protect those databases.',\n",
              "       'The trends discussed above highlight the need for organizations to defend themselves against a malware infection. They can do so by investing in a solution that both provides detailed reports about relevant system changes and uses VM sandboxing to examine questionable file behavior.',\n",
              "       'XMRig is an open-source CPU mining software used for the mining process of the Monero cryptocurrency, and first seen in-the-wild in May 2017.',\n",
              "       'Trend Micro researchers encountered a PowerGhost variant that infects Linux machines via EternalBlue, MSSQL, and Secure Shell (SSH) brute force attacks. The malware was previously known to target only Windows systems.',\n",
              "       'If no persistence technique was used, rebooting devices and changing passwords can halt fileless attacks since the threat only keeps data in RAM when the device is turned on. Behavior monitoring can also be employed to help observe and block malicious behavior.',\n",
              "       'We designed our pure-production honeypot to mimic a real system, including programmable logic controllers, a human-machine interface (HMI), and other components of an industrial control system (ICS).',\n",
              "       'We watched as this threat actor downloaded the ransomware through TeamViewer and continued with their routine, up to the point they left the ransom note. We even interacted and haggled with the threat actor through an exchange of emails.',\n",
              "       'On Nov. 12, we saw an interesting attack that disguised itself as a ransomware campaign, when in fact the threat actor behind it had simply renamed our files. Two days later, on Nov. 14, this threat actor came back to the system to delete files and leave open tabs of a porn site on our desktop.',\n",
              "       'As the research progressed, more and more threat actors found their way into our system, the weak security inviting them into what was potentially a lucrative opportunity.',\n",
              "       'ZDNet reported that the list consists of IP addresses and the usernames and passwords used by each for unlocking Telnet services, the port that allows these devices to be controlled through the internet.',\n",
              "       'The hacker composed the list by scanning the internet for exposed Telnet ports and by testing default and weak or common passwords. Since items on the list were dated from October to November 2019, some of the credentials might no longer work or had been changed over the succeeding months.',\n",
              "       'Using IoT search engines, ZDNet was able to verify that the devices were from all over the globe. Most of the devices were found on known internet service providers, confirming that these devices are either home routers or IoT devices. However, some of the IP addresses were on the networks of major cloud service providers.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ic7jRjf-7Nf",
        "colab_type": "text"
      },
      "source": [
        "## Labels Preprocessing and Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAinbkAG-7No",
        "colab_type": "code",
        "outputId": "5f026790-c776-487e-fe14-664f3aefa6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def join_labels(labels):\n",
        "    labels_joined = []\n",
        "    [labels_joined.append(','.join(label))for label in labels]\n",
        "    return labels_joined\n",
        "\n",
        "def encode_labels(labels_joined):                       # https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
        "    le = LabelEncoder()\n",
        "    list_labels = list(labels_joined)    \n",
        "    list_labels = le.fit_transform(list_labels)    # Give each malware label a numeric code\n",
        "    num_labels = len(list_labels)\n",
        "    num_cats = len(set(list_labels))\n",
        "    encoder = OneHotEncoder(sparse=False)               # Using numeric codes, create OneHot encoding\n",
        "    train_labels = list_labels.reshape((num_labels, 1))\n",
        "    Y = encoder.fit_transform(train_labels)\n",
        "    return Y, num_cats, le\n",
        "\n",
        "joined_labels = join_labels(label.values)\n",
        "enc_joined_labels, num_cats,le = encode_labels(joined_labels)\n",
        "print(num_cats)\n",
        "enc_joined_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjoF-JQUhAI8",
        "colab_type": "code",
        "outputId": "11553a06-7f24-4ea1-f0e1-e2e69612bb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Emotet', 'Mirai', 'nil'], dtype='<U6')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNrxTxzJ-7ON",
        "colab_type": "text"
      },
      "source": [
        "## Split to Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YQRVviASFEJ",
        "colab_type": "code",
        "outputId": "0c59adaf-05c4-46dc-dd20-9c9660c149ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "enc_joined_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWaFmWeo-7OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split base data into training and testing sets\n",
        "sentences = text['sentence'].values\n",
        "labels = label.values\n",
        "sentences_train, sentences_test, labels_train, labels_test = train_test_split(sentences, enc_joined_labels, test_size=0.25, random_state=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB8bZ8-o-7Oz",
        "colab_type": "code",
        "outputId": "0fe874d8-18c1-4347-9d48-61766043b081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"LABELS TRAIN:\\n\", labels_train, '\\n')\n",
        "print(\"LABELS TEST:\\n\", labels_test, '\\n')\n",
        "print(\"TRAIN LENGTH:\", len(labels_train), '\\n')    # len(set(labels_train)) results in TypeError: unhashable type: 'numpy.ndarray'\n",
        "print(\"TEST LENGTH:\", len(labels_test))   \n",
        "print(\"TYPE:\", type(sentences_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LABELS TRAIN:\n",
            " [[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]] \n",
            "\n",
            "LABELS TEST:\n",
            " [[0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]] \n",
            "\n",
            "TRAIN LENGTH: 89 \n",
            "\n",
            "TEST LENGTH: 30\n",
            "TYPE: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ow68rvqq-7PR",
        "colab_type": "code",
        "outputId": "fefc62c7-1ad7-4723-fb0c-9bb185af3d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# View sample training sentence\n",
        "print(sentences_train[0], '\\n')\n",
        "print(\"No. of characters:\", len(sentences_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After initial installation, the C2 capabilities begin. Emotet connects to C2 servers on various ports including, but not limited to: 20, 80, 443, 7080, 8443, and 50000. Typically, this all occurs using HTTP traffic to hard-coded IP addresses similar to what is shown below. \n",
            "\n",
            "No. of characters: 273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTkm9qstEEJv",
        "colab_type": "text"
      },
      "source": [
        "#USE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWS97kidEIqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url , trainable=False )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ECRKsDBv7j",
        "colab_type": "code",
        "outputId": "16e13d39-7605-41ff-8089-3d897ea40d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(tf.version)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v1.version' from '/usr/local/lib/python3.6/dist-packages/tensorflow_core/_api/v1/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpX9Vzb7GoNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dosuh2OMGCMP",
        "colab_type": "code",
        "outputId": "0b6d03f2-854c-4539-94ec-838410c0c922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(sentences_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA-51w8JKdAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDrayr-4HjPi",
        "colab_type": "code",
        "outputId": "cb74b77d-57b6-46cd-8e7a-7249c446b1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "labels_train.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAZ42k7XGuRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
        "# input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "# embedding = layers.Lambda(UniversalEmbedding,\n",
        "# \toutput_shape=(embed_size,))(input_text)\n",
        "# dense = layers.Dense(256, activation='relu')(embedding)\n",
        "# pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
        "# model = Model(inputs=[input_text], outputs=pred)\n",
        "# model.compile(loss='categorical_crossentropy', \n",
        "# \toptimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "854H71mTGtka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), \n",
        "    \tsignature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVxtycbrGukA",
        "colab_type": "code",
        "outputId": "8fca11ae-8abf-424e-8b45-decc7e2b9e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#build the Keras model in its standard Functional API,\n",
        "\n",
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "dense = layers.Dense(256, activation='relu')(embedding)\n",
        "pred = layers.Dense(3, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXQKuTZc6SPm",
        "colab_type": "code",
        "outputId": "d4c0409b-8a8f-45ce-edde-cd24bcae2cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "sentences_train[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['After initial installation, the C2 capabilities begin. Emotet connects to C2 servers on various ports including, but not limited to: 20, 80, 443, 7080, 8443, and 50000. Typically, this all occurs using HTTP traffic to hard-coded IP addresses similar to what is shown below.',\n",
              "       'Disney+ already has 28.6M subscribers  Iger will assume the role of executive chairman through 2021 according to Disney’s statement.',\n",
              "       'On Nov. 12, we saw an interesting attack that disguised itself as a ransomware campaign, when in fact the threat actor behind it had simply renamed our files. Two days later, on Nov. 14, this threat actor came back to the system to delete files and leave open tabs of a porn site on our desktop.',\n",
              "       'The scanning IP (aka, the bot) numbers are now climbing straight up. For example, during last recent 12 hours we have seen 263,250 different IPs scanning port 37215, and 19,403 IPs scanning port 52869.',\n",
              "       'The digital security solutions provider found that admins had protected just 10 of the 187 election-related domains with DMARC, a protocol useful for validating a sender’s authenticity.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lglo2v9eY4L0",
        "colab_type": "code",
        "outputId": "e55ebcee-d0f5-4914-b6fb-293f50f5bd6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_7 (Lambda)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 132,099\n",
            "Trainable params: 132,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp2VYioUkEWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import json\n",
        "# model_config = {}\n",
        "# model_config['class_name'] = model.__class__.__name__\n",
        "# model_config['config'] = model.get_config()\n",
        "# model_config\n",
        "# \"\"\"\n",
        "# model_config = json.dumps(model_config, default=get_json_type)\n",
        "# model_config = model_config.encode('utf-8')\n",
        "# h5dict['model_config'] = model_config\n",
        "# \"\"\"\n",
        "# #model_config = json.dumps(model_config)\n",
        "# #json.dumps(model_config)\n",
        "# model.get_config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8ZukO3T8Vhp",
        "colab_type": "code",
        "outputId": "5003c598-e344-4e54-8598-1e1f8f250eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "type(input_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC-S4gb_KL2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.python.keras import backend as K\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAka3EmqMb1r",
        "colab_type": "code",
        "outputId": "33835a1c-5d39-4a1d-c4f1-ae86ac00699f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "# # labels_train = to_categorical(labels_train)\n",
        "# # labels_test = to_categorical(labels_test) --> gives dimension (177, 45, 2, 2, 2, 2)\n",
        "\n",
        "# tf.keras.utils.normalize(labels_train, axis=-1, order=2)\n",
        "\n",
        "# print(labels_train.shape)\n",
        "\n",
        "labels_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8NbSHixEFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import model_from_json\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# from keras import backend\n",
        "# from keras.models import model_from_json\n",
        "# import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUvi5CeVSd6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change the learning rate ->increase to a limit\n",
        "\n",
        "myLearnRate =  0.01\n",
        "trainStep = tf.train.AdamOptimizer(learning_rate=myLearnRate)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_acc',\n",
        "                       min_delta=1e-3,\n",
        "                       patience=5,\n",
        "                       verbose=1,\n",
        "                       mode='auto',\n",
        "                       restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oJNPtswLCbS",
        "colab_type": "code",
        "outputId": "7b8d105b-bdb6-4055-852c-a84807e7442d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "# we train the model with the training datasets and validate its performance at the end of each training epoch with test datasets.\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  history = model.fit(sentences_train, \n",
        "            labels_train,\n",
        "            validation_data=(sentences_test, labels_test),\n",
        "            epochs=200,\n",
        "            batch_size=10,\n",
        "            callbacks = [monitor])\n",
        "\n",
        "  model.save_weights('./usetype_0000weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 89 samples, validate on 30 samples\n",
            "Epoch 1/200\n",
            "89/89 [==============================] - 12s 129ms/step - loss: 1.0465 - acc: 0.4944 - val_loss: 1.0139 - val_acc: 0.5000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 5s 62ms/step - loss: 0.8775 - acc: 0.5843 - val_loss: 0.9098 - val_acc: 0.5000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 6s 63ms/step - loss: 0.7640 - acc: 0.6180 - val_loss: 0.7958 - val_acc: 0.6333\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 5s 61ms/step - loss: 0.6644 - acc: 0.6966 - val_loss: 0.7408 - val_acc: 0.6333\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 6s 62ms/step - loss: 0.5687 - acc: 0.7978 - val_loss: 0.6544 - val_acc: 0.6333\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 6s 64ms/step - loss: 0.4952 - acc: 0.8539 - val_loss: 0.6156 - val_acc: 0.7000\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 6s 62ms/step - loss: 0.4278 - acc: 0.8764 - val_loss: 0.6058 - val_acc: 0.7000\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 6s 62ms/step - loss: 0.3786 - acc: 0.8652 - val_loss: 0.5488 - val_acc: 0.7333\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 6s 63ms/step - loss: 0.3288 - acc: 0.8989 - val_loss: 0.5619 - val_acc: 0.7000\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 5s 61ms/step - loss: 0.2978 - acc: 0.9101 - val_loss: 0.5480 - val_acc: 0.7000\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 5s 60ms/step - loss: 0.2616 - acc: 0.9326 - val_loss: 0.5503 - val_acc: 0.7000\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 6s 62ms/step - loss: 0.2350 - acc: 0.9438 - val_loss: 0.5109 - val_acc: 0.7333\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 6s 62ms/step - loss: 0.2127 - acc: 0.9551 - val_loss: 0.5220 - val_acc: 0.7000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBkwvbxOAqDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # serialize model to JSON\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model.json\", \"w\") as json_file:             t\n",
        "\n",
        "# model.save('modeluse.h5')\n",
        "# model.save('model.h5')\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gfffkKUDvnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# from keras import backend as K\n",
        "\n",
        "# KERAS_MODEL_NAME = \"/keras\"\n",
        "\n",
        "# # Save tf.keras model in HDF5 format.\n",
        "# tf.keras.models.save_model(model, KERAS_MODEL_NAME, save_format= 'h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKqmZgPjG_wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.keras.models.save_model(\n",
        "#     model,\n",
        "#     \"./model/iris_model.h5\",\n",
        "#     overwrite=True,\n",
        "#     include_optimizer=True\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou7cwqFCmrRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####NOT WORKING\n",
        "# model.evaluate(sentences_test, labels_test , verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3HoXmZX0gIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()\n",
        "# loss, acc = model.evaluate(sentences_test,  labels_test)\n",
        "# print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAHtY30nzgFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####NOT WORKING\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(sentences_test,  labels_test , verbose=2)\n",
        "# print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulQBK24YVIgP",
        "colab_type": "text"
      },
      "source": [
        "#PLOT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej-jH5_eRfAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n57tI4zBUnxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to visualize the loss and accuracy for the training and testing data based on the History callback.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "   acc = history.history['acc']\n",
        "   val_acc = history.history['val_acc']\n",
        "   loss = history.history['loss']\n",
        "   val_loss = history.history['val_loss']\n",
        "   x = range(1, len(acc) + 1)\n",
        "\n",
        "   plt.figure(figsize=(12, 5))\n",
        "   plt.subplot(1, 2, 1)\n",
        "   plt.plot(x, acc, 'b', label='Training acc')\n",
        "   plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "   plt.title('Training and validation accuracy')\n",
        "   plt.legend()\n",
        "   plt.subplot(1, 2, 2)\n",
        "   plt.plot(x, loss, 'b', label='Training loss')\n",
        "   plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "   plt.title('Training and validation loss')\n",
        "   plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd1hnE92WRKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGVbPBIVKGgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94aqtenH6hUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# from keras.models import load_model\n",
        "\n",
        "# model.save('./my_model.h5')\n",
        "#load saved model\n",
        "# Load pretrained model\n",
        "# model = tf.keras.models.load_model('keras_model/oov_model.h5')\n",
        "\n",
        "# # Check its architecture\n",
        "# model.summary()\n",
        "\n",
        "# loss, accuracy = model.evaluate(X_train, labels_train, verbose=False)\n",
        "# print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "# loss, accuracy = model.evaluate(X_test, labels_test, verbose=False)\n",
        "# print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwjSoOAzXe_e",
        "colab_type": "text"
      },
      "source": [
        "#IMPORTING SCRAPED FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPHpKC72x94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS8HRceDZnM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPfqpwnoXjPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"pred_withname.txt\"\n",
        "uploaded[file_name].decode(\"utf-8\")\n",
        "data = uploaded[file_name].decode(\"utf-8\").split(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waWRLnDQuHEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# myfile = open(file_name, 'r', encoding=\"utf-8\")\n",
        "# myfile = myfile.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV0Ktvjktg3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uploaded[file_name]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCnFiQ1IvY-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# myfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCOZcq6xrfdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8HDXh3zVMw_",
        "colab_type": "text"
      },
      "source": [
        "#PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzy-pUUhX2u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ScjR-FgLCRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######After we have the model trained and its weights saved to a file, it is ready to make predictions on new questions.\n",
        "\n",
        "# new_text = [\"Due to the worm like behavior, we all should be on the lookout for the port 37215 and 52869 scan traffic.\", \"Sometimes malware may appear on port 50000 ?\", \"there is no distinction.\", \"PoisonIvy opens a backdoor on TCP ports 6868 and 7777.\"]\n",
        "import numpy as np\n",
        "new_text = data\n",
        "\n",
        "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./usetype_weights.h5')  \n",
        "  \n",
        "  predicts = model.predict(new_text, batch_size=10)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8kN3EMJ4cZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-94iOHOOIW3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd    \n",
        "import numpy as np  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfVBsiSJJjZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiPxelnqIYmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame(labels\n",
        "                        )\n",
        "print(df_train)\n",
        "df_train = df_train[0]\n",
        "print(df_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d4TQNmz_bs04",
        "colab": {}
      },
      "source": [
        "# categories = df_train.categories.tolist()\n",
        "\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "predict_labels = [le.classes_[logit] for logit in predict_logits]\n",
        "# predict_labels[166]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZeVG7fxkLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlU-X_a7VQLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhFwsmXKws1b",
        "colab_type": "text"
      },
      "source": [
        "#SAVING PREDICTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sNNETDKrn0fK",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "# Print Timestamp At time of crawl\n",
        "datePosted = str(datetime.date.today())\n",
        "\n",
        "\n",
        "with open(f'predictions{datePosted}_iocwithname.txt', 'w') as f:\n",
        "    for item in predict_labels:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_lEQG_PYAFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "files.download(f'/content/predictions{datePosted}_iocwithname.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVd_SWaDVcFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_predict(expected, actual):\n",
        "   with open(expected, 'r') as f:\n",
        "       content = f.readlines()\n",
        "   \n",
        "   with open(actual, 'r') as f:\n",
        "       lines = f.readlines()\n",
        "    \n",
        "  #  print(content[2])\n",
        "\n",
        "   labels = []\n",
        "   for line in lines:\n",
        "       label = line.strip('\\n')\n",
        "       labels.append(label)\n",
        "\n",
        "   total_num = len(content)\n",
        "   num_correct = 0\n",
        "   index = 0\n",
        "   for s in range(len(content)):\n",
        "     print(content[s])\n",
        "     if content[s] == labels[s]:\n",
        "       print('CORRECT/n')\n",
        "       num_correct += 1\n",
        "     else:\n",
        "       print(\"WRONG\\n\")\n",
        "     index += 1\n",
        "\n",
        "\n",
        "   accuracy = num_correct/total_num * 100\n",
        "   print(\"ACCURACY:\", round(accuracy, 2))\n",
        "file_predict('labels_noname.txt','predictions2020-03-13_sent_noname.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4KVeymNs6WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBK8acX1WVOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in '/content/labels_withname.txt':\n",
        "  print(type(i))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxdbXfumRf0l",
        "colab_type": "text"
      },
      "source": [
        "#Saving model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY3hd9C9ixF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX2nxS_rmK28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "# model.fit(sentences_train, labels_train, epochs=42)\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model_USE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kedctvn7Re10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recreate the exact same model, including weights and optimizer.\n",
        "new_model = keras.models.load_model('my_model.h5')\n",
        "new_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpuQOZbwhqpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx3sIBzJkK9V",
        "colab_type": "text"
      },
      "source": [
        "#GROUP FILES BASED ON THEIR TYPE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-mYIggMAmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " with open(f'predictions{datePosted}.txt') as f1,open('pred_p11.txt') as f2,open(\"combinede.txt\",\"w\") as f3:\n",
        "...     for x,y in zip(f1,f2):\n",
        "...          f3.write(x.strip()+\" \"+y.strip()+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3V4r-X7NpLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stuff_to_write = []\n",
        "with open('combinede.txt') as f:\n",
        "    for line in f.readlines():\n",
        "      if 'Emotet,' in line:\n",
        "        stuff_to_write.append(line)\n",
        "\n",
        "\n",
        "with open('emotet_out2.txt','w') as f:\n",
        "    f.write(''.join(stuff_to_write))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbdzHcZIWJ31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stuff_to_write2 = []\n",
        "with open('combinede.txt') as f:\n",
        "    for line in f.readlines():\n",
        "      if 'Mirai,' in line:\n",
        "        stuff_to_write2.append(line)\n",
        "\n",
        "\n",
        "with open('mirai_out2.txt','w') as f:\n",
        "    f.write(''.join(stuff_to_write2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ8e7buuONbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to clear the emotet out file to redo anyth\n",
        "f = open('emotet_out2.txt', 'r+')\n",
        "f.truncate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaMQoGuoUybE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('mirai_out2.txt', 'r+')\n",
        "f.truncate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABf3iOA9WSU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja3WK5PTXMlQ",
        "colab_type": "text"
      },
      "source": [
        "#Regex to extract ip? ipv4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyi5lKzMXVqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0RZoEXfXWFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list1 = [re.findall(r'[0-9]+(?:\\.[0-9]+){3}',line) \n",
        "            for line in open('mirai_out2.txt')]\n",
        "########### remove empty lists in list\n",
        "\n",
        "list2 = [x for x in list1 if x != []]\n",
        "list2\n",
        "#remove dupliacated ip addr\n",
        "list_ipM = []\n",
        "for lists in list2:\n",
        "  lists = list(set(lists))\n",
        "  list_ipM += lists\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpZV_cmuZFB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_ipM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dpbqa3jddLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list3 = [re.findall(r'[0-9]+(?:\\.[0-9]+){3}',line) \n",
        "            for line in open('emotet_out2.txt')]\n",
        "\n",
        "########### remove empty lists in list\n",
        "\n",
        "list4 = [x for x in list3 if x != []]\n",
        "# list4\n",
        "#remove dupliacated ip addr\n",
        "list_ipE = []\n",
        "for lists in list4:\n",
        "  lists = list(set(lists))\n",
        "  list_ipE += lists\n",
        "\n",
        "list_ipE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4J1XOzqqcJA",
        "colab_type": "text"
      },
      "source": [
        "#Regex for ip? ipv6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGXT1XThqitd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# text = \" The C2/Exploit server for this botnet is2001:5000::/20 \"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmSSOK0frINN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b = re.findall(r'(([0-9a-fA-F]{0,4}:){1,7}[0-9a-fA-F]{0,4})', text)\n",
        "# # b = list(filter(lambda x: all([int(y) <= 255 for y in x.split('.')]), b))\n",
        "# print((b[0][0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRLswPuqBQpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ipv6_listM = [re.findall(r'(([0-9a-fA-F]{0,4}:){1,7}[0-9a-fA-F]{0,4})',line) \n",
        "            for line in open('mirai_out2.txt')]\n",
        "ipv6_listM = ipv6_listM[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GZdhKCK6DWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((ipv6_listM[0][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfVaM__XHFsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ipv6_listE = [re.findall(r'(([0-9a-fA-F]{0,4}:){1,7}[0-9a-fA-F]{0,4})',line) \n",
        "            for line in open('emotet_out2.txt')]\n",
        "ipv6_listE = ipv6_listE[0][0]\n",
        "print((ipv6_listE[0][0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts0d6GhLdehk",
        "colab_type": "text"
      },
      "source": [
        "#Regex for domains?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Be1NEyblS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_domainM = [re.findall(r'www.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',line) \n",
        "            for line in open('mirai_out2.txt')]\n",
        "\n",
        "list_domainM = [x for x in list_domainM if x != []]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV_b3XkSeo-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_domainE = [re.findall(r'www.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',line) \n",
        "            for line in open('emotet_out2.txt')]\n",
        "\n",
        "list_domainE = [x for x in list_domainE if x != []]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZYEZff_hSpB",
        "colab_type": "text"
      },
      "source": [
        "# Regex for port?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr14jnbvh9Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list_portE =  [re.findall(r'port\\s*(.*)\\s*and',line) \n",
        "#             for line in open('emotet_out2.txt')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWzEPBTdgZs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list_portE =  [re.findall(r'(?<=\\bport\\s)(\\w+)',line) \n",
        "#             for line in open('emotet_out2.txt')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ikx38EiI-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_portE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZqs1TfeiLsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parser_port = '<span[^>]*>\\s*([0-9]{2,})\\s*</\\s*span>'\n",
        "# p = re.compile(parser_port)\n",
        "\n",
        "# list_port = p.findall('/content/emotet_out2.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCY5fSKxkqxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nA_49rQksUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}